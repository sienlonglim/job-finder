{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "from time import perf_counter\n",
    "from functools import wraps\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrappers and request headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'Accept': 'text/html',\n",
    "           'Accept-Language': 'en-US',\n",
    "           'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_2) AppleWebKit/605.1.15 (KHTML, like Gecko) Safari/605.1.15 Version/13.0.4',\n",
    "           'Referer': 'http://www.google.com/'}\n",
    "\n",
    "def timeit(func):\n",
    "    @wraps(func)\n",
    "    def timeit_wrapper(*args, **kwargs):\n",
    "        start_time = perf_counter()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = perf_counter()\n",
    "        total_time = end_time - start_time\n",
    "        print(f'Function {func.__name__} Took {total_time:.4f} seconds - {args} {kwargs}')\n",
    "        return result\n",
    "    return timeit_wrapper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timeit\n",
    "def get_job_links(keyword, start_page, pages):    \n",
    "    '''Every linkedin job search page carries 25 jobs'''\n",
    "    def custom_selector(tag):\n",
    "        return tag.name == \"a\" and tag.has_attr(\"href\") and keyword in tag.get('href')\n",
    "    title = re.sub(' ', '%20', keyword)\n",
    "    keyword = re.sub(' ', '-', keyword) # This is used inside custom_selector's scope   \n",
    "    print(f'Searching for {keyword}')\n",
    "    job_links = []\n",
    "    position = start_page\n",
    "    currentJobId = None\n",
    "    try:\n",
    "        for page in tqdm(range(pages)):\n",
    "            # url = f\"https://www.linkedin.com/jobs/search/?currentJobId=3693533935&distance=25&geoId=102454443&keywords={title}&origin=JOB_SEARCH_PAGE_KEYWORD_HISTORY&refresh=true&start={position}\"\n",
    "            # url = f\"https://www.linkedin.com/jobs/search/?currentJobId=3693533935&distance=25&geoId=102454443&keywords={title}&currentJobId=3415227738&position=1&pageNum=0&start={position}\" \n",
    "            if not currentJobId:\n",
    "                url = f\"https://www.linkedin.com/jobs/search/?geoId=102454443&keywords={title}&location=Singapore&start={position}\"\n",
    "            else:\n",
    "                url = f\"https://www.linkedin.com/jobs/search/?currentJobId={currentJobId}&geoId=102454443&keywords={title}&location=Singapore&start={position}\"\n",
    "            response = requests.get(url, headers=headers)\n",
    "            soup = BeautifulSoup(response.text,'html.parser')\n",
    "            tags = soup.find_all(custom_selector)\n",
    "            for tag in tags:\n",
    "                link = tag.get('href')\n",
    "                job_links.append(link)\n",
    "            # Get the last jobid to start on the next page\n",
    "            currentJobId = re.findall('-([0-9]{6,})\\?', link)[0]\n",
    "            position += 25\n",
    "    except Exception as e:\n",
    "        print(f'Error at page {page}')\n",
    "        print(e)\n",
    "    finally:\n",
    "        return job_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_info(url):\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text,'html.parser')\n",
    "    info = {}\n",
    "\n",
    "    # Page title\n",
    "    title = soup.find('title')\n",
    "    if title:\n",
    "        info['company'] = title.text.split(' hiring')[0]\n",
    "\n",
    "    # Job title\n",
    "    job_title = soup.find('h1')\n",
    "    if job_title:\n",
    "        info['job_title'] = job_title.text\n",
    "\n",
    "    # Job level, type (full time etc), sector\n",
    "    criteria = soup.find_all('span', class_=\"description__job-criteria-text description__job-criteria-text--criteria\")\n",
    "    if criteria:\n",
    "        criteria = [x.text.strip(' \\n') for x in criteria]\n",
    "        try:\n",
    "            info['level'] = criteria[0]\n",
    "            info['job_type'] = criteria[1]\n",
    "            info['industry1'] = criteria[2]\n",
    "            info['industry2'] = criteria[3]\n",
    "        except Exception as e:\n",
    "            print(e, criteria)\n",
    "\n",
    "    # Job scope and requirements\n",
    "    descriptions = soup.find(class_ = \"show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden\")\n",
    "    if descriptions:\n",
    "        descriptions = [li.text for li in descriptions.find_all('li')]\n",
    "        line_by_line_desc = ''\n",
    "        experience = ''\n",
    "        spark = ''\n",
    "        degree = ''\n",
    "        for desc in descriptions:\n",
    "            if 'experience' in desc:\n",
    "                experience += desc + '\\n'\n",
    "            if ('PySpark' in desc) or ('Spark' in desc):\n",
    "                spark += desc + '\\n'\n",
    "            if 'degree' in desc:\n",
    "                degree += desc + '\\n'\n",
    "            line_by_line_desc += desc + '\\n'\n",
    "        info['descriptions'] = line_by_line_desc\n",
    "        info['degree'] = degree\n",
    "        info['experience'] = experience   \n",
    "        info['spark'] = spark \n",
    "\n",
    "    info['link'] = url            \n",
    "    \n",
    "    return info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input job search keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = 'data analyst'\n",
    "pages = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for data-analyst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:05<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function get_job_links Took 5.6528 seconds - ('data analyst',) {'start_page': 0, 'pages': 5}\n",
      "Retrieved links:  94 \n",
      "\n",
      "Getting job info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/94 [00:05<02:08,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range ['Mid-Senior level', 'Full-time', 'Information Technology']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 23/94 [00:27<01:27,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range ['Entry level', 'Full-time', 'Information Technology']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 51/94 [00:49<00:42,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range ['Mid-Senior level', 'Full-time', 'Information Technology']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [01:28<00:00,  1.07it/s]\n"
     ]
    }
   ],
   "source": [
    "links = get_job_links(keyword, start_page=0, pages=pages)\n",
    "print('Retrieved links: ', len(links), '\\n')\n",
    "main = {}\n",
    "print('Getting job info')\n",
    "for index, link in tqdm(enumerate(links), total = len(links), dynamic_ncols =True):\n",
    "    #print(f'Link {index}', end=' - ')\n",
    "    main[index] = get_job_info(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>job_title</th>\n",
       "      <th>level</th>\n",
       "      <th>job_type</th>\n",
       "      <th>experience</th>\n",
       "      <th>spark</th>\n",
       "      <th>degree</th>\n",
       "      <th>descriptions</th>\n",
       "      <th>industry1</th>\n",
       "      <th>industry2</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Shopee</td>\n",
       "      <td>Data Analyst - Marketing Analytics, Regional B...</td>\n",
       "      <td>Associate</td>\n",
       "      <td>Full-time</td>\n",
       "      <td></td>\n",
       "      <td>Develop smart and efficient solutions to repor...</td>\n",
       "      <td></td>\n",
       "      <td>Provide data and insight support for specific ...</td>\n",
       "      <td>Analyst, Marketing, and Information Technology</td>\n",
       "      <td>Technology, Information and Internet</td>\n",
       "      <td>https://sg.linkedin.com/jobs/view/data-analyst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>HCLTech</td>\n",
       "      <td>Data Analyst (SQL/Snowflake)</td>\n",
       "      <td>Associate</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>At least 3 years of data-related working exper...</td>\n",
       "      <td></td>\n",
       "      <td>Bachelor degree from a recognized tertiary ins...</td>\n",
       "      <td>Working closely with business end-users, marke...</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "      <td>https://sg.linkedin.com/jobs/view/data-analyst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>SHIELD</td>\n",
       "      <td>Data Analyst (Risk)</td>\n",
       "      <td>Associate</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>3-5 years of experience as a hands-on analyst...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Analysis of rich user and transaction data to ...</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>Technology, Information and Internet</td>\n",
       "      <td>https://sg.linkedin.com/jobs/view/data-analyst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>SISTIC Singapore</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Associate</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>At least 1-3 years of experience working in a ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Delve into our diverse event portfolio and dev...</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Entertainment Providers</td>\n",
       "      <td>https://sg.linkedin.com/jobs/view/data-analyst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Starbucks Coffee Singapore</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Associate</td>\n",
       "      <td>Full-time</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>At least a Bachelor degree in Statistics, Math...</td>\n",
       "      <td>Manage end-to-end data projects; identify issu...</td>\n",
       "      <td>Analyst and Information Technology</td>\n",
       "      <td>Food and Beverage Services</td>\n",
       "      <td>https://sg.linkedin.com/jobs/view/data-analyst...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       company  \\\n",
       "30                      Shopee   \n",
       "85                     HCLTech   \n",
       "61                      SHIELD   \n",
       "43            SISTIC Singapore   \n",
       "25  Starbucks Coffee Singapore   \n",
       "\n",
       "                                            job_title      level   job_type  \\\n",
       "30  Data Analyst - Marketing Analytics, Regional B...  Associate  Full-time   \n",
       "85                       Data Analyst (SQL/Snowflake)  Associate  Full-time   \n",
       "61                                Data Analyst (Risk)  Associate  Full-time   \n",
       "43                                       Data Analyst  Associate  Full-time   \n",
       "25                                      Data Analyst   Associate  Full-time   \n",
       "\n",
       "                                           experience  \\\n",
       "30                                                      \n",
       "85  At least 3 years of data-related working exper...   \n",
       "61   3-5 years of experience as a hands-on analyst...   \n",
       "43  At least 1-3 years of experience working in a ...   \n",
       "25                                                      \n",
       "\n",
       "                                                spark  \\\n",
       "30  Develop smart and efficient solutions to repor...   \n",
       "85                                                      \n",
       "61                                                      \n",
       "43                                                      \n",
       "25                                                      \n",
       "\n",
       "                                               degree  \\\n",
       "30                                                      \n",
       "85  Bachelor degree from a recognized tertiary ins...   \n",
       "61                                                      \n",
       "43                                                      \n",
       "25  At least a Bachelor degree in Statistics, Math...   \n",
       "\n",
       "                                         descriptions  \\\n",
       "30  Provide data and insight support for specific ...   \n",
       "85  Working closely with business end-users, marke...   \n",
       "61  Analysis of rich user and transaction data to ...   \n",
       "43  Delve into our diverse event portfolio and dev...   \n",
       "25  Manage end-to-end data projects; identify issu...   \n",
       "\n",
       "                                         industry1  \\\n",
       "30  Analyst, Marketing, and Information Technology   \n",
       "85                          Information Technology   \n",
       "61                                         Analyst   \n",
       "43                          Information Technology   \n",
       "25              Analyst and Information Technology   \n",
       "\n",
       "                               industry2  \\\n",
       "30  Technology, Information and Internet   \n",
       "85         IT Services and IT Consulting   \n",
       "61  Technology, Information and Internet   \n",
       "43               Entertainment Providers   \n",
       "25            Food and Beverage Services   \n",
       "\n",
       "                                                 link  \n",
       "30  https://sg.linkedin.com/jobs/view/data-analyst...  \n",
       "85  https://sg.linkedin.com/jobs/view/data-analyst...  \n",
       "61  https://sg.linkedin.com/jobs/view/data-analyst...  \n",
       "43  https://sg.linkedin.com/jobs/view/data-analyst...  \n",
       "25  https://sg.linkedin.com/jobs/view/data-analyst...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(main, orient='index')\n",
    "df = df[~(df['company'].isnull() | df['job_title'].isnull() | df['level'].isnull())]\n",
    "subset_duplicates = ['company', 'job_title', 'level', 'job_type', 'degree', 'experience', 'spark', 'descriptions', 'industry1']\n",
    "df = df.drop_duplicates(subset=subset_duplicates)\n",
    "df = df[['company', 'job_title', 'level', 'job_type', 'experience', 'spark', 'degree', 'descriptions', 'industry1', 'industry2', 'link']]\n",
    "df = df.sort_values(by=['level', 'spark', 'company', 'job_type'],\n",
    "                    ascending= [True, False, True, True])\n",
    "print(len(df))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(f\"{keyword}_{datetime.now().strftime('%Y-%m-%d-%M%S')}.xlsx\", engine='xlsxwriter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'data analyst_2023-12-20-0245.xlsx')\n",
      "(1, 'data engineer_2023-12-20-0033.xlsx')\n",
      "(2, 'data scientist_2023-12-20-5814.xlsx')\n",
      "(3, 'data-analyst_2023-12-20-0737.xlsx')\n",
      "(4, 'data-analyst_2023-12-20-3727.xlsx')\n",
      "(5, 'MAIN_2023-12-20.xlsx')\n"
     ]
    }
   ],
   "source": [
    "excel_files = [file for file in os.listdir() if file.endswith('xlsx')]\n",
    "for item in enumerate(excel_files):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df = pd.DataFrame(columns = ['company', 'job_title', 'level', 'job_type', 'experience', 'spark', 'degree', 'descriptions', 'industry1', 'industry2', 'link'])\n",
    "\n",
    "file_indices= [0,1,2,3,4]\n",
    "for idx in file_indices:\n",
    "    sub_df = pd.read_excel(excel_files[idx], index_col=0)\n",
    "    main_df = pd.concat([main_df, sub_df])\n",
    "    main_df = main_df.drop_duplicates(subset=subset_duplicates)\n",
    "\n",
    "len(main_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df.to_excel(f\"MAIN_{datetime.now().strftime('%Y-%m-%d')}.xlsx\", engine='xlsxwriter')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
